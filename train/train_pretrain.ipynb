{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, random_split, WeightedRandomSampler\n",
    "from datetime import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from dataset_pretrain import Data_Loader\n",
    "from model.lossfunction import LayerSegLoss_1, LayerSegLoss_2\n",
    "from model.generator import Generator\n",
    "from model.reconstructor import Reconstructor\n",
    "from model.discriminator import Discriminator\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from utils.monitor import Monitor\n",
    "import numpy as np\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "def train(net_G, net_D, net_R, device, data_path, lr_G=0.00001, lr_D=0.0001, lr_R=0.0001, epochs=40, batch_size=1, image_size=256, save_path='', generator_backbone='', discriminator_backbone='', cross_vaild=''):\n",
    "    time = datetime.now()\n",
    "    date_time = time.strftime('%Y%m%d')\n",
    "\n",
    "    # Data Loading\n",
    "    transform = transforms.Compose([transforms.Resize((image_size, image_size)),\n",
    "                                    transforms.ToTensor(),\n",
    "                                    transforms.Normalize(0, 1)\n",
    "                                    ])\n",
    "\n",
    "    train_dataset = Data_Loader(data_path + '/LS_{}_nonoverlap_train'.format(cross_vaild), transform)\n",
    "    valid_dataset = Data_Loader(data_path + '/LS_{}_nonoverlap_test'.format(cross_vaild), transform)\n",
    "\n",
    "    # sampler setting\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   drop_last=True\n",
    "                                                   )\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,\n",
    "                                                   batch_size=batch_size,\n",
    "                                                   shuffle=True,\n",
    "                                                   drop_last=True\n",
    "                                                   )\n",
    "\n",
    "    # Monitor\n",
    "    my_monitor = Monitor(epochs=epochs, device=device,\n",
    "                         train_loss_name_list=['Generator_Loss', 'Discriminator_Loss'],\n",
    "                         val_loss_name_list=['Generator_Loss_val'],\n",
    "                         lr_name_list=['lr_G', 'lr_D'],\n",
    "                         train_dataset=train_loader,\n",
    "                         val_dataset=valid_loader\n",
    "                         )\n",
    "\n",
    "    # Optimizer & Loss Function\n",
    "    optimizer_G = torch.optim.Adam(net_G.parameters(), lr=lr_G, betas=(0.5, 0.999))\n",
    "    optimizer_D = torch.optim.Adam(net_D.parameters(), lr=lr_D, betas=(0.5, 0.999))\n",
    "    optimizer_R = torch.optim.Adam(net_R.parameters(), lr=lr_R, betas=(0.5, 0.999))\n",
    "\n",
    "    scheduler_G = torch.optim.lr_scheduler.StepLR(optimizer=optimizer_G, step_size=30, gamma=0.5)\n",
    "    scheduler_D = torch.optim.lr_scheduler.StepLR(optimizer=optimizer_D, step_size=30, gamma=0.5)\n",
    "    scheduler_R = torch.optim.lr_scheduler.StepLR(optimizer=optimizer_R, step_size=60, gamma=0.5)\n",
    "\n",
    "    criterion_LS = LayerSegLoss_1()\n",
    "    criterion_D = nn.BCELoss()\n",
    "\n",
    "    best_loss_G = float('inf')\n",
    "    best_loss_D = float('inf')\n",
    "\n",
    "    # Start train in epoch\n",
    "    for epoch in range(epochs):\n",
    "        my_monitor.train_start(optimizer_list=[optimizer_G, optimizer_D])\n",
    "        '''\n",
    "            Start train\n",
    "        '''\n",
    "        for image, masks, image_cropping, masks_cropping, real_layer_images, _ in train_loader:\n",
    "            net_G.train()\n",
    "            net_D.train()\n",
    "            net_R.train()\n",
    "            # Data Loading\n",
    "            image = image.to(device=device, dtype=torch.float32)\n",
    "            masks = masks.to(device=device, dtype=torch.float32)\n",
    "            image_cropping = image_cropping.to(device=device, dtype=torch.float32)\n",
    "            masks_cropping = masks_cropping.to(device=device, dtype=torch.float32)\n",
    "            real_layer_images = real_layer_images.to(device=device, dtype=torch.float32)\n",
    "\n",
    "            # Train the discriminator\n",
    "            optimizer_D.zero_grad()\n",
    "\n",
    "            zeros_layer = torch.zeros_like(masks_cropping)\n",
    "\n",
    "            label_real = torch.cat((masks_cropping, masks_cropping), dim=1)\n",
    "            label_real_2 = torch.cat((masks, masks), dim=1)\n",
    "            label_fake = torch.cat((masks, zeros_layer), dim=1)\n",
    "\n",
    "            fake_image = net_G(image, masks)\n",
    "\n",
    "            dis_mask = torch.clone(masks)\n",
    "            dis_mask = torch.cat((dis_mask, dis_mask), dim=1)\n",
    "\n",
    "            loss_D_real = criterion_D(net_D(image_cropping) * dis_mask, label_real)\n",
    "            loss_D_real_2 = criterion_D(net_D(real_layer_images) * dis_mask, label_real_2)\n",
    "            loss_D_fake = criterion_D(net_D(fake_image) * dis_mask, label_fake)\n",
    "\n",
    "            loss_D = (loss_D_real + loss_D_fake + loss_D_real_2) / 3\n",
    "\n",
    "            loss_D.backward()\n",
    "            optimizer_D.step()\n",
    "\n",
    "            # Train the Generator and Reconstructor\n",
    "            optimizer_G.zero_grad()\n",
    "            optimizer_R.zero_grad()\n",
    "\n",
    "            pre_layer = net_G(image, masks)\n",
    "\n",
    "            pre_image, x = net_R(image, pre_layer, masks)\n",
    "            print(x[0])\n",
    "            pre_masks = net_D(pre_layer) * dis_mask\n",
    "\n",
    "            loss_GR = criterion_LS(org_image=image, org_masks=masks, real_layer=real_layer_images,\n",
    "                                         pre_layer=pre_layer, recon_image=pre_image, pre_masks=pre_masks)\n",
    "\n",
    "            loss_GR.backward()\n",
    "            optimizer_G.step()\n",
    "            optimizer_R.step()\n",
    "\n",
    "            my_monitor.set_loss(loss_list=[loss_GR, loss_D])\n",
    "\n",
    "        '''\n",
    "            Start valid\n",
    "        '''\n",
    "        my_monitor.val_start()\n",
    "        net_G.eval()\n",
    "        net_D.eval()\n",
    "        net_R.eval()\n",
    "        with torch.no_grad():\n",
    "            for image, masks, image_cropping, masks_cropping, real_layer_images, _ in valid_loader:\n",
    "                # Data Loading\n",
    "                image = image.to(device=device, dtype=torch.float32)\n",
    "                masks = masks.to(device=device, dtype=torch.float32)\n",
    "                image_cropping = image_cropping.to(device=device, dtype=torch.float32)\n",
    "                masks_cropping = masks_cropping.to(device=device, dtype=torch.float32)\n",
    "                real_layer_images = real_layer_images.to(device=device, dtype=torch.float32)\n",
    "\n",
    "                dis_mask = torch.clone(masks)\n",
    "                dis_mask = torch.cat((dis_mask, dis_mask), dim=1)\n",
    "\n",
    "                org_mask_all = torch.sum(masks, 1).unsqueeze(1)\n",
    "                org_mask_all[org_mask_all != 0] = 1\n",
    "\n",
    "                pre_layer = net_G(image, masks)\n",
    "\n",
    "                pre_image, x = net_R(image, pre_layer, masks)\n",
    "                print(x[0])\n",
    "                pre_masks = net_D(pre_layer) * dis_mask\n",
    "\n",
    "                loss_GR_val = criterion_LS(org_image=image, org_masks=masks, real_layer=real_layer_images,\n",
    "                                                 pre_layer=pre_layer, recon_image=pre_image, pre_masks=pre_masks)\n",
    "\n",
    "                my_monitor.set_loss(loss_list=[loss_GR_val])\n",
    "                my_monitor.set_output_image(number=4, image_list=[image, pre_layer, pre_image, pre_masks, org_mask_all, x])\n",
    "\n",
    "            my_monitor.show_val_result()\n",
    "        \n",
    "        my_monitor.epoch_summary()\n",
    "\n",
    "        # Save parameters\n",
    "        if my_monitor.get_recent_best_loss(loss_name='Generator_Loss') < best_loss_G:\n",
    "            best_loss_G = my_monitor.get_recent_best_loss(loss_name='Generator_Loss')\n",
    "            if isinstance(net_G, torch.nn.DataParallel):\n",
    "                torch.save(net_G.module.state_dict(),\n",
    "                           '{}/best_Generator_Pre_{}_{}_{}.pth'.format(save_path, generator_backbone, discriminator_backbone, cross_vaild))\n",
    "                torch.save(net_R.module.state_dict(),\n",
    "                           '{}/best_Reconstructor_Pre_{}_{}_{}.pth'.format(save_path, generator_backbone, discriminator_backbone, cross_vaild))\n",
    "\n",
    "        if my_monitor.get_recent_best_loss(loss_name='Discriminator_Loss') < best_loss_D:\n",
    "            best_loss_D = my_monitor.get_recent_best_loss(loss_name='Discriminator_Loss')\n",
    "            if isinstance(net_D, torch.nn.DataParallel):\n",
    "                torch.save(net_D.module.state_dict(),\n",
    "                           '{}/best_Discriminator_Pre_{}_{}_{}.pth'.format(save_path, generator_backbone, discriminator_backbone, cross_vaild))\n",
    "       \n",
    "        # scheduler_G.step()\n",
    "        # scheduler_D.step()\n",
    "        scheduler_R.step()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "    layer = 2\n",
    "    image_size = 256\n",
    "    generator_backbone = 'transunet'\n",
    "    discriminator_backbone = 'unet'\n",
    "\n",
    "    net_generator = Generator(n_layers=layer, backbone=generator_backbone)\n",
    "    net_discriminator = Discriminator(n_layers=layer, backbone=discriminator_backbone)\n",
    "    net_reconstructor = Reconstructor()\n",
    "\n",
    "    net_generator = nn.DataParallel(net_generator)\n",
    "    net_discriminator = nn.DataParallel(net_discriminator)\n",
    "    net_reconstructor = nn.DataParallel(net_reconstructor)\n",
    "\n",
    "    net_generator.to(device=device)\n",
    "    net_discriminator.to(device=device)\n",
    "    net_reconstructor.to(device=device)\n",
    "\n",
    "    data_path = ROOT_PATH + '/Data'\n",
    "    save_path = ROOT_PATH + '/parameters/pre_train'\n",
    "    cross_vaild = 'K1'\n",
    "\n",
    "    train(net_G=net_generator, net_D=net_discriminator, net_R=net_reconstructor, \n",
    "          device=device, data_path=data_path,\n",
    "          epochs=250, batch_size=12, lr_G=0.00001, lr_D=0.000001, lr_R=0.00001, image_size=image_size,\n",
    "          generator_backbone=generator_backbone, \n",
    "          discriminator_backbone=discriminator_backbone,\n",
    "          cross_vaild=cross_vaild, save_path=save_path)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
