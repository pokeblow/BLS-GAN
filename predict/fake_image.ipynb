{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import sys\n",
    "\n",
    "root_dir = os.path.abspath(os.path.join(os.getcwd(), \"../..\"))\n",
    "sys.path.append(root_dir)\n",
    "\n",
    "from dataset_fake import Data_Loader\n",
    "from model.generator import Generator\n",
    "from model.reconstructor import Reconstructor\n",
    "from model.discriminator import Discriminator\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import torch.nn as nn\n",
    "\n",
    "ROOT_PATH = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "cross_vaild = 'K1'\n",
    "\n",
    "data_path = ROOT_PATH + '/Data/LS_{}_nonoverlap_test'.format(cross_vaild)\n",
    "transform = transforms.Compose([transforms.Resize((256, 256)),\n",
    "                                transforms.ToTensor(),\n",
    "                                ])\n",
    "\n",
    "image_dataset = Data_Loader(data_path, transform)\n",
    "data = torch.utils.data.DataLoader(dataset=image_dataset,\n",
    "                                   batch_size=1,\n",
    "                                   drop_last=True\n",
    "                                   )\n",
    "\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "layer = 2\n",
    "image_size = 256\n",
    "generator_backbone = 'transunet'\n",
    "discriminator_backbone = 'unet'\n",
    "\n",
    "net_generator = Generator(n_layers=layer, backbone=generator_backbone)\n",
    "net_discriminator = Discriminator(n_layers=layer, backbone=discriminator_backbone)\n",
    "net_reconstructor = Reconstructor(if_CP=False)\n",
    "\n",
    "net_G = nn.DataParallel(net_generator)\n",
    "net_D = nn.DataParallel(net_discriminator)\n",
    "net_R = nn.DataParallel(net_reconstructor)\n",
    "\n",
    "net_G.to(device=device)\n",
    "net_D.to(device=device)\n",
    "net_R.to(device=device)\n",
    "\n",
    "def predict(net_G, net_D, net_R, image, masks):\n",
    "    parameter_path = ROOT_PATH + '/parameters'\n",
    "    \n",
    "    pretrain_path = '{}/best_Generator_Main_transunet_unet_K1.pth'.format(parameter_path)\n",
    "    state_dict = torch.load(pretrain_path)\n",
    "    net_G.module.load_state_dict(state_dict)\n",
    "\n",
    "    pretrain_path = '{}/best_Reconstructor_Main_transunet_unet_K1.pth'.format(parameter_path)\n",
    "    state_dict = torch.load(pretrain_path)\n",
    "    net_R.module.load_state_dict(state_dict)\n",
    "\n",
    "    pretrain_path = '{}/best_Discriminator_Main_transunet_unet_K1.pth'.format(parameter_path)\n",
    "    state_dict = torch.load(pretrain_path)\n",
    "    net_D.module.load_state_dict(state_dict)\n",
    "\n",
    "    dis_mask = torch.clone(masks)\n",
    "    dis_mask = torch.cat((dis_mask, dis_mask), dim=1)\n",
    "\n",
    "    pre_layer = net_G(image, masks)\n",
    "\n",
    "    pre_image, x = net_R(image, pre_layer, masks)\n",
    "    print(x[0])\n",
    "    pre_masks = net_D(pre_layer) * dis_mask\n",
    "\n",
    "    cv2.imwrite(ROOT_PATH + '/results/fake_overlap/recon_image_{}.jpg'.format(image_name),\n",
    "                pre_image.cpu().detach().numpy()[0][0] * 255)\n",
    "    cv2.imwrite(ROOT_PATH + '/results/fake_overlap/upper_layer_{}.jpg'.format(image_name),\n",
    "                pre_layer.cpu().detach().numpy()[0][1] * 255)\n",
    "    cv2.imwrite(ROOT_PATH + '/results/fake_overlap/lower_layer_{}.jpg'.format(image_name),\n",
    "                pre_layer.cpu().detach().numpy()[0][0] * 255)\n",
    "    cv2.imwrite(ROOT_PATH + '/results/fake_overlap/upper_mask_{}.bmp'.format(image_name),\n",
    "                pre_masks.cpu().detach().numpy()[0][1] * 255)\n",
    "    cv2.imwrite(ROOT_PATH + '/results/fake_overlap/lower_mask_{}.bmp'.format(image_name),\n",
    "                pre_masks.cpu().detach().numpy()[0][0] * 255)\n",
    "\n",
    "\n",
    "\n",
    "parameter_path = ROOT_PATH + '/parameters'\n",
    "for batch_idx, batch in enumerate(data):\n",
    "    image, layer_masks, image_cropping, masks_cropping, real_layer_images, name = batch\n",
    "    print('{} / {}'.format(batch_idx + 1, len(data)))\n",
    "    '''\n",
    "    model output\n",
    "    '''\n",
    "    net_R.eval()\n",
    "    net_D.eval()\n",
    "    net_G.eval()\n",
    "\n",
    "    image = image.to(device=device, dtype=torch.float32)\n",
    "    masks = layer_masks.to(device=device, dtype=torch.float32)\n",
    "    image_cropping = image_cropping.to(device=device, dtype=torch.float32)\n",
    "    masks_cropping = masks_cropping.to(device=device, dtype=torch.float32)\n",
    "    real_layer_images = real_layer_images.to(device=device, dtype=torch.float32)\n",
    "\n",
    "    image_name = name[0]\n",
    "    print(image_name)\n",
    "\n",
    "    # print('Pre Done')\n",
    "    # predict(net_G, net_D, net_R, image, masks, mode='Pre')\n",
    "    print('Main Done')\n",
    "    predict(net_G, net_D, net_R, image, masks, mode='Main')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
